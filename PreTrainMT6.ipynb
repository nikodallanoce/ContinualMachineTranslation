{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import MT5Tokenizer, MT5ForConditionalGeneration, MT5Config\n",
    "import torch\n",
    "from noise_functions.MT5NoiseFunction import MT5NoiseFunction\n",
    "from noise_functions.MT6NoiseFunction import MT6NoiseFunction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:45:44.911834800Z",
     "start_time": "2023-11-29T08:45:41.964347100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MT5Config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 6\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MT5TokenizerFast, T5ForConditionalGeneration\n\u001B[1;32m      4\u001B[0m tok \u001B[38;5;241m=\u001B[39m MT5TokenizerFast\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnikodallanoce/mt5-cc4-vanilla-32k-5\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m MT6(\n\u001B[0;32m----> 6\u001B[0m         \u001B[43mMT5Config\u001B[49m(num_layers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m6\u001B[39m, d_kv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, d_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m, num_heads\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m, d_ff\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2048\u001B[39m, vocab_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(tok), max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m,\n\u001B[1;32m      7\u001B[0m                   tie_word_embeddings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[1;32m      8\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# model = MT6(MT5Config(vocab_size=len(tok), tie_word_embeddings=True))\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'MT5Config' is not defined"
     ]
    }
   ],
   "source": [
    "from MT6 import MT6\n",
    "from transformers import MT5TokenizerFast, T5ForConditionalGeneration\n",
    "\n",
    "tok = MT5TokenizerFast.from_pretrained(\"nikodallanoce/mt5-cc4-vanilla-32k-5\")\n",
    "model = MT6(\n",
    "        MT5Config(num_layers=6, d_kv=64, d_model=512, num_heads=8, d_ff=2048, vocab_size=len(tok), max_length=128,\n",
    "                  tie_word_embeddings=True))\n",
    "model.train(False)\n",
    "# model = MT6(MT5Config(vocab_size=len(tok), tie_word_embeddings=True))\n",
    "model.num_parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:17:15.983987Z",
     "start_time": "2023-11-28T16:17:12.993939200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "text/plain": "MBartForConditionalGeneration(\n  (model): MBartModel(\n    (shared): Embedding(32100, 512, padding_idx=1)\n    (encoder): MBartEncoder(\n      (embed_tokens): Embedding(32100, 512, padding_idx=1)\n      (embed_positions): MBartLearnedPositionalEmbedding(1026, 512)\n      (layers): ModuleList(\n        (0-5): 6 x MBartEncoderLayer(\n          (self_attn): MBartAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): MBartDecoder(\n      (embed_tokens): Embedding(32100, 512, padding_idx=1)\n      (embed_positions): MBartLearnedPositionalEmbedding(1026, 512)\n      (layers): ModuleList(\n        (0-5): 6 x MBartDecoderLayer(\n          (self_attn): MBartAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MBartAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=512, out_features=32100, bias=False)\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MT6 import MT6\n",
    "from transformers import MT5TokenizerFast, T5ForConditionalGeneration, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "#tok = MT5TokenizerFast.from_pretrained(\"nikodallanoce/mt5-cc4-vanilla-32k-5\")\n",
    "tok = AutoTokenizer.from_pretrained(\"google/t5-v1_1-small\")\n",
    "cuda_dev = \"cpu\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        \"/data/n.dallanoce/weights/mt5_ft_en-fr_M1F1_t5_mbart/checkpoint-85000\",\n",
    "        )\n",
    "model = model.to(cuda_dev)\n",
    "model.train(False)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:45:46.874348100Z",
     "start_time": "2023-11-29T08:45:44.909810300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"cc100\", lang=\"en\",\n",
    "                       cache_dir=\"/data/n.dallanoce/cc100/huggingface\",\n",
    "                       split=f\"train[{4096}:{4096 * 2}]\",\n",
    "                       verification_mode='no_checks')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:47:12.953339600Z",
     "start_time": "2023-11-28T10:47:11.317246700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: wants, and he will be so lost. His whole life is in chairs. (Having a\n",
      " \n",
      " \n",
      "source: wants, and <extra_id_0> His whole life <extra_id_1> chairs. (Having a\n"
     ]
    }
   ],
   "source": [
    "index = 167\n",
    "sent = dataset[index]['text']\n",
    "src_sent, tgt_sent = MT5NoiseFunction(0.35, 3).compute(sent, seed=index)\n",
    "print(f\"original: {sent} \\n \\nsource: {src_sent}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T11:05:19.326900300Z",
     "start_time": "2023-11-28T11:05:19.326900300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: Officials say an escape route is complete and workers trapped for over two weeks will be freed soon. \n",
      " \n",
      "source: Officials say an <extra_id_0> route <extra_id_1> workers trapped <extra_id_2> two weeks will be freed soon.\n"
     ]
    }
   ],
   "source": [
    "from noise_functions.MT5NoiseFunction import MT5NoiseFunction\n",
    "\n",
    "index = 2\n",
    "#sent = dataset[index]['text']\n",
    "sent = \"Officials say an escape route is complete and workers trapped for over two weeks will be freed soon.\"\n",
    "\n",
    "src_sent, tgt_sent = MT5NoiseFunction(0.35, 3).compute(sent, seed=index)\n",
    "#src_sent = sent + \"</s> \"+ src_sent\n",
    "print(f\"original: {sent} \\n \\nsource: {src_sent}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T11:09:33.025417200Z",
     "start_time": "2023-11-28T11:09:32.984421500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/n.dallanoce/anaconda3/envs/deeptorch/lib/python3.9/site-packages/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " prediction: ['<pad><extra_id_0> emergency <extra_id_1> for <extra_id_2> within <extra_id_3></s>'] \n",
      " \n",
      " source: Officials say an <extra_id_0> route <extra_id_1> workers trapped <extra_id_2> two weeks will be freed soon. \n",
      " \n",
      " label: <extra_id_0> escape <extra_id_1> is complete and <extra_id_2> for over <extra_id_3>\n"
     ]
    }
   ],
   "source": [
    "tok_sent = tok(src_sent, return_tensors=\"pt\")\n",
    "tok_sent[\"input_ids\"] = tok_sent[\"input_ids\"].to(cuda_dev)\n",
    "tok_sent[\"attention_mask\"] = tok_sent[\"attention_mask\"].to(cuda_dev)\n",
    "sequence_ids = model.generate(**tok_sent, max_new_tokens=128, num_beams=4)\n",
    "sequences = tok.batch_decode(sequence_ids, skip_special_tokens=False)\n",
    "print(f\" prediction: {sequences} \\n \\n source: {src_sent} \\n \\n label: {tgt_sent}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T11:19:18.209735400Z",
     "start_time": "2023-11-28T11:19:17.901528200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Il y a deux jours, jâ€™ai perdu mon chat.']\n"
     ]
    }
   ],
   "source": [
    "to_translate = \"translate English to French: Two days ago I lost my cat.\"\n",
    "tok_sent = tok(to_translate, return_tensors=\"pt\", max_length=128, padding=\"max_length\", truncation=True)\n",
    "tok_sent[\"input_ids\"] = tok_sent[\"input_ids\"].to(cuda_dev)\n",
    "#tok_sent[\"attention_mask\"] = tok_sent[\"attention_mask\"].to(cuda_dev)\n",
    "sequence_ids = model.generate(**tok_sent, max_new_tokens=128, num_beams=5,\n",
    "                              #bos_token_id=tok.bos_token_id, eos_token_id=tok.eos_token_id\n",
    "                              )\n",
    "sequences = tok.batch_decode(sequence_ids, skip_special_tokens=True)\n",
    "print(sequences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:48:39.340437600Z",
     "start_time": "2023-11-29T08:48:38.819520600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[13959,  1566,    12,  2379,    10,  2759,   477,   977,    27,  1513,\n            82,  1712,     5,     1,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_sent[\"input_ids\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:48:59.785474700Z",
     "start_time": "2023-11-29T08:48:59.724918500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
