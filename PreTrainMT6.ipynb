{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import MT5Tokenizer, MT5ForConditionalGeneration, MT5Config\n",
    "import torch\n",
    "from transformers.utils import is_torch_fx_proxy\n",
    "\n",
    "from noise_functions.MT6NoiseFunction import MT6NoiseFunction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T11:41:52.356554Z",
     "end_time": "2023-04-04T11:41:57.000757Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def model_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_all_mb = (param_size + buffer_size) / 1024 ** 2\n",
    "    return size_all_mb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T11:42:24.354186Z",
     "end_time": "2023-04-04T11:42:24.367220Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load the configuration of '/home/n.dallanoce/PyCharm/pretraining/weights/mt6_loss/checkpoint-5120'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/n.dallanoce/PyCharm/pretraining/weights/mt6_loss/checkpoint-5120' is the correct path to a directory containing a config.json file",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mHFValidationError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeptorch\\lib\\site-packages\\transformers\\configuration_utils.py:620\u001B[0m, in \u001B[0;36mPretrainedConfig._get_config_dict\u001B[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    619\u001B[0m     \u001B[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001B[39;00m\n\u001B[1;32m--> 620\u001B[0m     resolved_config_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    621\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    622\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfiguration_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    623\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    624\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    625\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    626\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_auth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    629\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    630\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    633\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    634\u001B[0m     commit_hash \u001B[38;5;241m=\u001B[39m extract_commit_hash(resolved_config_file, commit_hash)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeptorch\\lib\\site-packages\\transformers\\utils\\hub.py:409\u001B[0m, in \u001B[0;36mcached_file\u001B[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001B[0m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    408\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[1;32m--> 409\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    410\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    411\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    412\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    413\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    414\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    415\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    416\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    417\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    418\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    419\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_auth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    420\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    421\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    423\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m RepositoryNotFoundError:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeptorch\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:112\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m arg_name \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrepo_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto_id\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m--> 112\u001B[0m     \u001B[43mvalidate_repo_id\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m arg_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m arg_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeptorch\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:160\u001B[0m, in \u001B[0;36mvalidate_repo_id\u001B[1;34m(repo_id)\u001B[0m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m repo_id\u001B[38;5;241m.\u001B[39mcount(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 160\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HFValidationError(\n\u001B[0;32m    161\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRepo id must be in the form \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrepo_name\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnamespace/repo_name\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    162\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrepo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Use `repo_type` argument if needed.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    163\u001B[0m     )\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m REPO_ID_REGEX\u001B[38;5;241m.\u001B[39mmatch(repo_id):\n",
      "\u001B[1;31mHFValidationError\u001B[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/n.dallanoce/PyCharm/pretraining/weights/mt6_loss/checkpoint-5120'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m tok_en \u001B[38;5;241m=\u001B[39m MT5Tokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgoogle/mt5-base\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      3\u001B[0m cuda_dev \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 5\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mMT5ForConditionalGeneration\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/home/n.dallanoce/PyCharm/pretraining/weights/mt6_loss/checkpoint-5120\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(cuda_dev)\n\u001B[0;32m      8\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeptorch\\lib\\site-packages\\transformers\\modeling_utils.py:2079\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m   2077\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(config, PretrainedConfig):\n\u001B[0;32m   2078\u001B[0m     config_path \u001B[38;5;241m=\u001B[39m config \u001B[38;5;28;01mif\u001B[39;00m config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m pretrained_model_name_or_path\n\u001B[1;32m-> 2079\u001B[0m     config, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mconfig_class\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[0;32m   2080\u001B[0m         config_path,\n\u001B[0;32m   2081\u001B[0m         cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n\u001B[0;32m   2082\u001B[0m         return_unused_kwargs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   2083\u001B[0m         force_download\u001B[38;5;241m=\u001B[39mforce_download,\n\u001B[0;32m   2084\u001B[0m         resume_download\u001B[38;5;241m=\u001B[39mresume_download,\n\u001B[0;32m   2085\u001B[0m         proxies\u001B[38;5;241m=\u001B[39mproxies,\n\u001B[0;32m   2086\u001B[0m         local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[0;32m   2087\u001B[0m         use_auth_token\u001B[38;5;241m=\u001B[39muse_auth_token,\n\u001B[0;32m   2088\u001B[0m         revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[0;32m   2089\u001B[0m         subfolder\u001B[38;5;241m=\u001B[39msubfolder,\n\u001B[0;32m   2090\u001B[0m         _from_auto\u001B[38;5;241m=\u001B[39mfrom_auto_class,\n\u001B[0;32m   2091\u001B[0m         _from_pipeline\u001B[38;5;241m=\u001B[39mfrom_pipeline,\n\u001B[0;32m   2092\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2093\u001B[0m     )\n\u001B[0;32m   2094\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2095\u001B[0m     model_kwargs \u001B[38;5;241m=\u001B[39m kwargs\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeptorch\\lib\\site-packages\\transformers\\configuration_utils.py:538\u001B[0m, in \u001B[0;36mPretrainedConfig.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[0;32m    460\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[0;32m    461\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_pretrained\u001B[39m(\u001B[38;5;28mcls\u001B[39m, pretrained_model_name_or_path: Union[\u001B[38;5;28mstr\u001B[39m, os\u001B[38;5;241m.\u001B[39mPathLike], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPretrainedConfig\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    462\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    463\u001B[0m \u001B[38;5;124;03m    Instantiate a [`PretrainedConfig`] (or a derived class) from a pretrained model configuration.\u001B[39;00m\n\u001B[0;32m    464\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    536\u001B[0m \u001B[38;5;124;03m    assert unused_kwargs == {\"foo\": False}\u001B[39;00m\n\u001B[0;32m    537\u001B[0m \u001B[38;5;124;03m    ```\"\"\"\u001B[39;00m\n\u001B[1;32m--> 538\u001B[0m     config_dict, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mget_config_dict(pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    539\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_type:\n\u001B[0;32m    540\u001B[0m         logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[0;32m    541\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou are using a model of type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m to instantiate a model of type \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    542\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. This is not supported for all configurations of models and can yield errors.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    543\u001B[0m         )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeptorch\\lib\\site-packages\\transformers\\configuration_utils.py:565\u001B[0m, in \u001B[0;36mPretrainedConfig.get_config_dict\u001B[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[0;32m    563\u001B[0m original_kwargs \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(kwargs)\n\u001B[0;32m    564\u001B[0m \u001B[38;5;66;03m# Get config dict associated with the base config file\u001B[39;00m\n\u001B[1;32m--> 565\u001B[0m config_dict, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_get_config_dict(pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    566\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict:\n\u001B[0;32m    567\u001B[0m     original_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeptorch\\lib\\site-packages\\transformers\\configuration_utils.py:641\u001B[0m, in \u001B[0;36mPretrainedConfig._get_config_dict\u001B[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[0;32m    638\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m    639\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    640\u001B[0m         \u001B[38;5;66;03m# For any other exception, we throw a generic error.\u001B[39;00m\n\u001B[1;32m--> 641\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[0;32m    642\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt load the configuration of \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_model_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. If you were trying to load it\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    643\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m from \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/models\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, make sure you don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt have a local directory with the same\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    644\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name. Otherwise, make sure \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_model_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is the correct path to a directory\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    645\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m containing a \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfiguration_file\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m file\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    646\u001B[0m         )\n\u001B[0;32m    648\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    649\u001B[0m     \u001B[38;5;66;03m# Load config dict\u001B[39;00m\n\u001B[0;32m    650\u001B[0m     config_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_dict_from_json_file(resolved_config_file)\n",
      "\u001B[1;31mOSError\u001B[0m: Can't load the configuration of '/home/n.dallanoce/PyCharm/pretraining/weights/mt6_loss/checkpoint-5120'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/n.dallanoce/PyCharm/pretraining/weights/mt6_loss/checkpoint-5120' is the correct path to a directory containing a config.json file"
     ]
    }
   ],
   "source": [
    "from transformers import MT5TokenizerFast\n",
    "\n",
    "tok_en = MT5TokenizerFast.from_pretrained(\"nikodallanoce/mt5-cc4-vanilla-32k-5\")\n",
    "\n",
    "cuda_dev = \"cpu\"\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained(\n",
    "    \"/home/n.dallanoce/PyCharm/pretraining/weights/mt6_loss/checkpoint-5120\")\n",
    "model = model.to(cuda_dev)\n",
    "model.train(False)\n",
    "print(model_size(model))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cc100/en to C:/data/n.dallanoce/cc100/huggingface/cc100/en-lang=en/0.0.0/8159941b93eb06d0288bb80be26ddfe8213c0c5e33286619c85ad8e1ee0eb91c...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/87.3G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d297dc8c414c4c9f8851491e7358bba9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"cc100\", lang=\"en\",\n",
    "                                cache_dir=\"/data/n.dallanoce/cc100/huggingface\",\n",
    "                                split=f\"train[{4096}:{4096*2}]\",\n",
    "                                verification_mode='no_checks')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: Read about what EEI’s International Programs has accomplished in the first-half of 2018\n",
      " \n",
      " \n",
      "source: <extra_id_0> what EEI’s International <extra_id_1> has accomplished <extra_id_2> of <extra_id_3>\n"
     ]
    }
   ],
   "source": [
    "index = 111\n",
    "sent = dataset[index]['text']\n",
    "src_sent, tgt_sent = MT6NoiseFunction().compute_for_mt5(sent, seed=index, noise_density=0.35)\n",
    "print(f\"original: {sent} \\n \\nsource: {src_sent}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m index \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m111\u001B[39m\n\u001B[1;32m----> 2\u001B[0m sent \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m[index][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      3\u001B[0m src_sent, tgt_sent \u001B[38;5;241m=\u001B[39m MT6NoiseFunction()\u001B[38;5;241m.\u001B[39mcompute(sent, seed\u001B[38;5;241m=\u001B[39mindex)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moriginal: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msent\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124msource: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msrc_sent\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "index = 111\n",
    "sent = dataset[index]['text']\n",
    "src_sent, tgt_sent = MT6NoiseFunction().compute(sent, seed=index)\n",
    "print(f\"original: {sent} \\n \\nsource: {src_sent}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'src_sent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m input_ids \u001B[38;5;241m=\u001B[39m tok_en(\u001B[43msrc_sent\u001B[49m, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39minput_ids\n\u001B[0;32m      2\u001B[0m sequence_ids \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate(input_ids, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m)\n\u001B[0;32m      3\u001B[0m sequences \u001B[38;5;241m=\u001B[39m tok_en\u001B[38;5;241m.\u001B[39mbatch_decode(sequence_ids, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'src_sent' is not defined"
     ]
    }
   ],
   "source": [
    "input_ids = tok_en(src_sent, return_tensors=\"pt\").input_ids\n",
    "sequence_ids = model.generate(input_ids.to(cuda_dev), max_length=64)\n",
    "sequences = tok_en.batch_decode(sequence_ids, skip_special_tokens=False)\n",
    "print(f\"prediction: {sequences} \\n \\nlabel: {tgt_sent}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
