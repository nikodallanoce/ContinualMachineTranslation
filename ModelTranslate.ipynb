{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-09T09:04:07.341842300Z",
     "start_time": "2023-06-09T09:04:05.727260400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: pyarrow._fs.FileInfo size changed, may indicate binary incompatibility. Expected 64 from C header, got 88 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: pyarrow._fs.FileSelector size changed, may indicate binary incompatibility. Expected 48 from C header, got 72 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import MT5Tokenizer, MT5ForConditionalGeneration, MT5Config\n",
    "import torch\n",
    "from transformers.utils import is_torch_fx_proxy\n",
    "from MT6 import MT6\n",
    "from transformers import MT5TokenizerFast, T5ForConditionalGeneration\n",
    "from noise_functions.MT6NoiseFunction import MT6NoiseFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type t5 to instantiate a model of type mt5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": "76935552"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Config\n",
    "\n",
    "tokenizer = MT5TokenizerFast.from_pretrained(\"nikodallanoce/mt5-cc4-vanilla-32k-5\")\n",
    "\n",
    "cuda_dev = \"cpu\"\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained(\"/home/n.dallanoce/PyCharm/pretraining/weights/mt6_pre_en-fr(M1)_delta/checkpoint-100000\")\n",
    "#model = T5ForConditionalGeneration(MT5Config(vocab_size=len(tokenizer), tie_word_embeddings=False, dense_act_fn = \"gelu_new\",  feed_forward_proj= \"gated-gelu\"))\n",
    "# model = MT6(\n",
    "#         MT5Config(num_layers=6, d_model=512, num_heads=8, d_ff=2048, vocab_size=len(tokenizer), max_length=128,\n",
    "#                   tie_word_embeddings=True))\n",
    "model = model.to(cuda_dev)\n",
    "model.train(False)\n",
    "model.num_parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T09:06:29.142058700Z",
     "start_time": "2023-06-09T09:06:25.921549700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "MT5Config {\n  \"d_ff\": 1024,\n  \"d_kv\": 64,\n  \"d_model\": 512,\n  \"decoder_start_token_id\": 0,\n  \"dense_act_fn\": \"gelu_new\",\n  \"dropout_rate\": 0.1,\n  \"eos_token_id\": 1,\n  \"feed_forward_proj\": \"gated-gelu\",\n  \"initializer_factor\": 1.0,\n  \"is_encoder_decoder\": true,\n  \"is_gated_act\": true,\n  \"layer_norm_epsilon\": 1e-06,\n  \"model_type\": \"mt5\",\n  \"num_decoder_layers\": 8,\n  \"num_heads\": 6,\n  \"num_layers\": 8,\n  \"pad_token_id\": 0,\n  \"relative_attention_max_distance\": 128,\n  \"relative_attention_num_buckets\": 32,\n  \"tie_word_embeddings\": false,\n  \"tokenizer_class\": \"T5Tokenizer\",\n  \"transformers_version\": \"4.27.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 32103\n}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T00:29:56.327295200Z",
     "start_time": "2023-06-08T00:29:56.311458100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "T5Config {\n  \"_name_or_path\": \"google/t5-v1_1-small\",\n  \"architectures\": [\n    \"T5ForConditionalGeneration\"\n  ],\n  \"d_ff\": 1024,\n  \"d_kv\": 64,\n  \"d_model\": 512,\n  \"decoder_start_token_id\": 0,\n  \"dense_act_fn\": \"gelu_new\",\n  \"dropout_rate\": 0.1,\n  \"eos_token_id\": 1,\n  \"feed_forward_proj\": \"gated-gelu\",\n  \"initializer_factor\": 1.0,\n  \"is_encoder_decoder\": true,\n  \"is_gated_act\": true,\n  \"layer_norm_epsilon\": 1e-06,\n  \"model_type\": \"t5\",\n  \"num_decoder_layers\": 8,\n  \"num_heads\": 6,\n  \"num_layers\": 8,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"relative_attention_max_distance\": 128,\n  \"relative_attention_num_buckets\": 32,\n  \"tie_word_embeddings\": false,\n  \"transformers_version\": \"4.27.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 32103\n}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_config = T5ForConditionalGeneration.from_pretrained(\"google/t5-v1_1-small\").config\n",
    "new_config.vocab_size = len(tokenizer)\n",
    "new_config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T10:29:09.253952800Z",
     "start_time": "2023-06-08T10:29:07.008806200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at t5-small were not used when initializing T5ForConditionalGeneration: ['decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-small and are newly initialized: ['encoder.block.0.layer.1.DenseReluDense.wi_0.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_1.weight', 'encoder.block.1.layer.1.DenseReluDense.wi_0.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_1.weight', 'encoder.block.3.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.2.layer.1.DenseReluDense.wi_0.weight', 'encoder.block.4.layer.1.DenseReluDense.wi_0.weight', 'encoder.block.4.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.1.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.2.layer.1.DenseReluDense.wi_1.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_0.weight', 'encoder.block.5.layer.1.DenseReluDense.wi_0.weight', 'encoder.block.3.layer.1.DenseReluDense.wi_0.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_0.weight', 'encoder.block.0.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.5.layer.1.DenseReluDense.wi_1.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5TokenizerFast\n",
    "\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"t5-small\")\n",
    "\n",
    "cuda_dev = \"cpu\"\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    \"t5-small\", max_length=128, is_gated_act=True, tie_word_embeddings=True, feed_forward_proj=True)\n",
    "model = model.to(cuda_dev)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:50:04.918855400Z",
     "start_time": "2023-06-04T12:50:02.947123600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "['Translat', 'e', 'English', 'to', 'German', ':', '</s>']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_tok = tokenizer(\"Translate English to German: \")\n",
    "tokenizer.batch_decode(inp_tok[\"input_ids\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:41:39.171326600Z",
     "start_time": "2023-06-04T12:41:39.164291900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-1.2188e+00, -4.3750e+00, -7.9062e+00,  ...,  2.0469e+00,\n          3.0938e+00, -6.5938e+00],\n        [-1.4438e+01,  8.1250e+00, -1.1719e+00,  ...,  1.1562e+01,\n          4.8438e+00,  9.1000e+01],\n        [ 8.1250e+00,  3.6250e+00, -1.9453e+00,  ..., -4.6250e+00,\n          1.3125e+01,  2.1375e+01],\n        ...,\n        [-4.5117e-01, -3.3594e-01, -3.8867e-01,  ..., -2.0996e-01,\n         -2.0000e+00, -9.1406e-01],\n        [-1.0234e+00, -8.0859e-01,  4.3555e-01,  ..., -5.9326e-02,\n         -9.2188e-01, -9.2969e-01],\n        [ 1.0078e+00,  1.5234e-01, -2.4902e-01,  ..., -1.8555e-01,\n         -2.7148e-01,  1.7969e+00]], requires_grad=True)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.shared.weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T11:18:22.544760600Z",
     "start_time": "2023-06-04T11:18:22.543757300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-0.6602,  0.1572,  0.1777,  ..., -0.4199, -0.5938, -0.9609],\n        [-0.2480,  0.3672,  0.8125,  ..., -0.0371, -1.0156, -0.5508],\n        [-0.3555, -0.3613, -0.0688,  ..., -0.3672,  0.4180, -0.1465],\n        ...,\n        [-0.6055,  0.1631,  0.1729,  ..., -0.3359, -0.5703, -0.9531],\n        [-0.7070,  0.2041,  0.1914,  ..., -0.3418, -0.5625, -0.9219],\n        [-0.6914,  0.1426,  0.1738,  ..., -0.4082, -0.5273, -0.9297]],\n       requires_grad=True)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head.weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T11:18:31.204397200Z",
     "start_time": "2023-06-04T11:18:31.198397300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = MT5ForConditionalGeneration(\n",
    "    MT5Config(num_layers=6, d_model=512, num_heads=8, d_ff=2048, vocab_size=len(tokenizer), max_length=133,\n",
    "              tie_word_embeddings=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T09:06:41.868462700Z",
     "start_time": "2023-06-09T09:06:40.591131Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'tile'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#tokenizer = MT5Tokenizer.from_pretrained(\"google/mt5-small\", max_length = 128)\u001B[39;00m\n\u001B[1;32m      2\u001B[0m inp_tok \u001B[38;5;241m=\u001B[39m tokenizer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthis <extra_id_0> is very hot.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      3\u001B[0m                     text_target\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDas Haus ist wunderbar.\u001B[39m\u001B[38;5;124m\"\u001B[39m, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m out_gen \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43minp_tok\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput_ids\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m tokenizer\u001B[38;5;241m.\u001B[39mbatch_decode(out_gen, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/anaconda3/envs/deeptorch/lib/python3.8/site-packages/torch/autograd/grad_mode.py:26\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m():\n\u001B[0;32m---> 26\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/deeptorch/lib/python3.8/site-packages/transformers/generation/utils.py:1406\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, **kwargs)\u001B[0m\n\u001B[1;32m   1400\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1401\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_return_sequences has to be 1, but is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgeneration_config\u001B[38;5;241m.\u001B[39mnum_return_sequences\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m when doing\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1402\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m greedy search.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1403\u001B[0m         )\n\u001B[1;32m   1405\u001B[0m     \u001B[38;5;66;03m# 11. run greedy search\u001B[39;00m\n\u001B[0;32m-> 1406\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgreedy_search\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1407\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1408\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1409\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1410\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1411\u001B[0m \u001B[43m        \u001B[49m\u001B[43meos_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meos_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1412\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_scores\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_scores\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1413\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1414\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1415\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1416\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1418\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_contrastive_search_gen_mode:\n\u001B[1;32m   1419\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m generation_config\u001B[38;5;241m.\u001B[39mnum_return_sequences \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/envs/deeptorch/lib/python3.8/site-packages/transformers/generation/utils.py:2252\u001B[0m, in \u001B[0;36mGenerationMixin.greedy_search\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001B[0m\n\u001B[1;32m   2249\u001B[0m \u001B[38;5;66;03m# if eos_token was found in one sentence, set sentence to finished\u001B[39;00m\n\u001B[1;32m   2250\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m eos_token_id_tensor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2251\u001B[0m     unfinished_sequences \u001B[38;5;241m=\u001B[39m unfinished_sequences\u001B[38;5;241m.\u001B[39mmul(\n\u001B[0;32m-> 2252\u001B[0m         \u001B[43mnext_tokens\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtile\u001B[49m(eos_token_id_tensor\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mne(eos_token_id_tensor\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m))\u001B[38;5;241m.\u001B[39mprod(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m   2253\u001B[0m     )\n\u001B[1;32m   2255\u001B[0m \u001B[38;5;66;03m# stop when each sentence is finished, or if we exceed the maximum length\u001B[39;00m\n\u001B[1;32m   2256\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m unfinished_sequences\u001B[38;5;241m.\u001B[39mmax() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m stopping_criteria(input_ids, scores):\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Tensor' object has no attribute 'tile'"
     ]
    }
   ],
   "source": [
    "#tokenizer = MT5Tokenizer.from_pretrained(\"google/mt5-small\", max_length = 128)\n",
    "inp_tok = tokenizer(\"this <extra_id_0> is very hot.\",\n",
    "                    text_target=\"Das Haus ist wunderbar.\", return_tensors=\"pt\")\n",
    "out_gen = model.generate(inp_tok['input_ids'], max_new_tokens=128)\n",
    "tokenizer.batch_decode(out_gen, skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T09:06:55.346484300Z",
     "start_time": "2023-06-09T09:06:55.046383100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(10.2929, grad_fn=<NllLossBackward>)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = model(**inp_tok).loss\n",
    "loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:50:08.626654600Z",
     "start_time": "2023-06-04T12:50:08.543338Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "T5Config {\n  \"_name_or_path\": \"t5-small\",\n  \"architectures\": [\n    \"T5ForConditionalGeneration\"\n  ],\n  \"d_ff\": 2048,\n  \"d_kv\": 64,\n  \"d_model\": 512,\n  \"decoder_start_token_id\": 0,\n  \"dense_act_fn\": \"relu\",\n  \"dropout_rate\": 0.1,\n  \"eos_token_id\": 1,\n  \"feed_forward_proj\": \"relu\",\n  \"initializer_factor\": 1.0,\n  \"is_encoder_decoder\": true,\n  \"is_gated_act\": true,\n  \"layer_norm_epsilon\": 1e-06,\n  \"max_length\": 128,\n  \"model_type\": \"t5\",\n  \"n_positions\": 512,\n  \"num_decoder_layers\": 6,\n  \"num_heads\": 8,\n  \"num_layers\": 6,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"relative_attention_max_distance\": 128,\n  \"relative_attention_num_buckets\": 32,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"early_stopping\": true,\n      \"length_penalty\": 2.0,\n      \"max_length\": 200,\n      \"min_length\": 30,\n      \"no_repeat_ngram_size\": 3,\n      \"num_beams\": 4,\n      \"prefix\": \"summarize: \"\n    },\n    \"translation_en_to_de\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to German: \"\n    },\n    \"translation_en_to_fr\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to French: \"\n    },\n    \"translation_en_to_ro\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to Romanian: \"\n    }\n  },\n  \"transformers_version\": \"4.24.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 32128\n}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:48:20.303215700Z",
     "start_time": "2023-06-04T12:48:20.261747Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
